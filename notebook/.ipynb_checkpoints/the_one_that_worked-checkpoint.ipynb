{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8680c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajag\\Desktop\\convolve\\convolve_epoch_1\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f32355d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajag\\Desktop\\convolve\\convolve_epoch_1\\data\n"
     ]
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03920323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c472176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom settings \n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc43a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data \n",
    "with open('train.json', 'r') as f:\n",
    "    dict_train = json.load(f)\n",
    "\n",
    "df = pd.DataFrame.from_dict(dict_train, orient='index')\n",
    "df.reset_index(level=0, inplace=True)\n",
    "df.rename(columns = {'index':'log',0:'status'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96d5d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "df_parsed = df.copy(deep=True)\n",
    "df_parsed[\"log\"]= df_parsed[\"log\"].str.split(\":\", n = 3, expand = False)\n",
    "df_temp = df_parsed.copy(deep=True)\n",
    "df_temp = pd.DataFrame(df_parsed['log'].to_list(), columns=['log1','log2','log3','log4'])\n",
    "df_temp['status'] = df_parsed['status']\n",
    "df4 = df_temp[df_temp['log4'].isnull()].copy(deep=True)\n",
    "df5 = df_temp[df_temp['log4'].notnull()].copy(deep=True)\n",
    "train1 = df4.drop(['log4', 'log1', 'log2'], axis=1)\n",
    "train2 = df5.drop(['log3', 'log1', 'log2'], axis=1)\n",
    "train1.rename(columns = {'log3':'log'}, inplace = True)\n",
    "train2.rename(columns = {'log4':'log'}, inplace = True)\n",
    "tmp_list = [train1,train2]\n",
    "train = pd.concat(tmp_list)\n",
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15938d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1\n",
    "# doing a 50 50 split\n",
    "\n",
    "train_new1 = train.sample(frac=1)\n",
    "\n",
    "fraud_df = train_new1.loc[train_new1['status'] == \"abnormal\"]\n",
    "non_fraud_df = train_new1.loc[train_new1['status'] == \"normal\"][:69692]\n",
    "\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "balanced_train1 = normal_distributed_df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12bb6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 5, custom sampler\n",
    "total_normal = train[train[\"status\"] == \"normal\"]\n",
    "total_abnormal = train[train[\"status\"] == \"abnormal\"]\n",
    "\n",
    "sampled_total_normal = total_normal.sample(n=69692)\n",
    "\n",
    "normal_distributed_df = pd.concat([total_abnormal, sampled_total_normal])\n",
    "\n",
    "balanced_train2 = normal_distributed_df.sample(frac=1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a8f70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal      46892\n",
       "abnormal    46892\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 2\n",
    "# Over sampling- making copies of the minority class\n",
    "\n",
    "X = train.drop('status',axis=1)\n",
    "y = train['status']\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "#split data into test and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
    "#combine them back for resampling\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "# separate minority and majority classes\n",
    "negative = train_data[train_data.status==\"abnormal\"]\n",
    "positive = train_data[train_data.status==\"normal\"]\n",
    "# upsample minority\n",
    "pos_upsampled = resample(positive,\n",
    " replace=True, # sample with replacement\n",
    " n_samples=len(negative), # match number in majority class\n",
    " random_state=27) # reproducible results\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([negative, pos_upsampled])\n",
    "# check new class counts\n",
    "upsampled.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0f1ef9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abnormal    2676259\n",
       "normal      2676259\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 3\n",
    "# downsample majority\n",
    "\n",
    "neg_downsampled = resample(negative,\n",
    " replace=True, # sample with replacement\n",
    " n_samples=len(positive), # match number in minority class\n",
    " random_state=27) # reproducible results\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([positive, neg_downsampled])\n",
    "# check new class counts\n",
    "downsampled.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d58d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c31f4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed = test.copy(deep=True)\n",
    "df_parsed[\" Log\"]= df_parsed[\" Log\"].str.split(\":\", n = 3, expand = False)\n",
    "df_temp = df_parsed.copy(deep=True)\n",
    "df_temp = pd.DataFrame(df_parsed[' Log'].to_list(), columns=['log1','log2','log3','log4'])\n",
    "df_temp['ID'] = df_parsed['ID']\n",
    "df4 = df_temp[df_temp['log4'].isnull()].copy(deep=True)\n",
    "df5 = df_temp[df_temp['log4'].notnull()].copy(deep=True)\n",
    "train1 = df4.drop(['log4', 'log1', 'log2'], axis=1)\n",
    "train2 = df5.drop(['log3', 'log1', 'log2'], axis=1)\n",
    "train1.rename(columns = {'log3':'log'}, inplace = True)\n",
    "train2.rename(columns = {'log4':'log'}, inplace = True)\n",
    "tmp_list = [train1,train2]\n",
    "temp_train = pd.concat(tmp_list)\n",
    "test = temp_train\n",
    "# test = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3509a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.fillna(test.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a57e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.sort_values(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0f267be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import xgboost as xgb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.b\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "443ee3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = downsampled.copy(deep=True)\n",
    "train = train.sample(frac = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b9ec873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal      267899\n",
       "abnormal    267353\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccfaf118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajag\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(508489, 10000) (508489,)\n",
      "(26763, 10000) (26763,)\n"
     ]
    }
   ],
   "source": [
    "from nltk import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# for xgboost\n",
    "tokenizer = TweetTokenizer()\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize, max_features = 10000)\n",
    "full_text = list(train['log'].values) + list(test['log'].values)\n",
    "vectorizer.fit(full_text)\n",
    "train_vectorized = vectorizer.transform(train['log'])\n",
    "test_vectorized = vectorizer.transform(test['log'])\n",
    "\n",
    "# vectorizer1 = TfidfVectorizer(ngram_range=(1, 5), analyzer='char', tokenizer=tokenizer.tokenize, stop_words='english',max_features=10000)\n",
    "# full_text = list(train['log'].values) + list(test['log'].values)\n",
    "# vectorizer1.fit(full_text)\n",
    "# train_vectorized1 = vectorizer1.transform(train['log'])\n",
    "# test_vectorized1 = vectorizer1.transform(test['log'])\n",
    "\n",
    "train[\"status\"] = train[\"status\"].map({\"abnormal\":0,\"normal\":1})\n",
    "y = train['status']\n",
    "\n",
    "# train_matrix = hstack((train_vectorized, train_vectorized1))\n",
    "# test_matrix = hstack((test_vectorized, test_vectorized1))\n",
    "\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(train_vectorized,y, test_size = 0.05, random_state = 42)\n",
    "print(X_train1.shape,Y_train1.shape)\n",
    "print(X_test1.shape,Y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "601d5f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4148751    0\n",
       "4091747    0\n",
       "4128801    0\n",
       "4136660    0\n",
       "4100908    0\n",
       "          ..\n",
       "4091799    0\n",
       "1979050    1\n",
       "3953756    1\n",
       "4093255    0\n",
       "4083382    0\n",
       "Name: status, Length: 535252, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dfb494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = xgb.XGBClassifier(\n",
    " learning_rate =0.2,\n",
    " n_estimators=1000,\n",
    "#  max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    "#  nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7955cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is tokenized X and Y \n",
    "train_model3 = model3.fit(X_train1, Y_train1)\n",
    "pred3 = train_model3.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15930f0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13410\n",
      "           1       1.00      1.00      1.00     13353\n",
      "\n",
      "    accuracy                           1.00     26763\n",
      "   macro avg       1.00      1.00      1.00     26763\n",
      "weighted avg       1.00      1.00      1.00     26763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test1,pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78cf51bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = train_model3.predict(test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cddc7418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8aaf6258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kernel terminated for reason 1001\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J03-U11 RAS KERNEL INFO generating core.6463\\n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   log  ID\n",
       "0                  kernel terminated for reason 1001\\n   0\n",
       "1  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   1\n",
       "2  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   2\n",
       "3       J03-U11 RAS KERNEL INFO generating core.6463\\n   3\n",
       "4  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17dec18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_new = test.copy(deep=True)\n",
    "sub_new['status'] = pred\n",
    "sub_new.rename(columns = {'status':' Label'}, inplace = True)\n",
    "sub_new = sub_new.drop(['log'], axis=1)\n",
    "sub_new[\" Label\"] = sub_new[\" Label\"].map({0:\"abnormal\",1:\"normal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de37eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_new[\" Label\"] = sub_new[\" Label\"].map({0:\"abnormal\",1:\"normal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c60b8026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_new= sub_new.loc[:,~sub_new.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2b61fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     Label\n",
       "1   1  abnormal\n",
       "2   2  abnormal\n",
       "4   4  abnormal\n",
       "6   6  abnormal\n",
       "8   8  abnormal"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_new[sub_new[\" Label\"] == \"abnormal\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "627e7c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3804720309087855"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub_new[sub_new[\" Label\"] == \"abnormal\"])/len(sub_new)\n",
    "# earlier 0.3804333949269276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecc1cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_new.to_csv(r'C:\\Users\\rajag\\Desktop\\convolve\\convolve_epoch_1\\submission\\submission_11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9dc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45863326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fcb220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f3390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa32b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec815a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82db5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb3217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b590a4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fbb234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ecc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65edccd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fcbc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06690e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796e9d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9dfd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e30ac1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1982cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b7004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c0707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e6fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16071906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866f903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc48c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c10683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8796ecbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c28d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6019d76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af2e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca010ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab899845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6adff7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53006707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595460d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab5cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2e3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

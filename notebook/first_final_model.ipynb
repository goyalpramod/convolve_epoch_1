{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8680c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajag\\Desktop\\convolve\\convolve_epoch_1\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f32355d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajag\\Desktop\\convolve\\convolve_epoch_1\\data\n"
     ]
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03920323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c472176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom settings \n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc43a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data \n",
    "with open('train.json', 'r') as f:\n",
    "    dict_train = json.load(f)\n",
    "\n",
    "df = pd.DataFrame.from_dict(dict_train, orient='index')\n",
    "df.reset_index(level=0, inplace=True)\n",
    "df.rename(columns = {'index':'log',0:'status'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d5d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "df_parsed = df.copy(deep=True)\n",
    "df_parsed[\"log\"]= df_parsed[\"log\"].str.split(\":\", n = 3, expand = False)\n",
    "df_temp = df_parsed.copy(deep=True)\n",
    "df_temp = pd.DataFrame(df_parsed['log'].to_list(), columns=['log1','log2','log3','log4'])\n",
    "df_temp['status'] = df_parsed['status']\n",
    "df4 = df_temp[df_temp['log4'].isnull()].copy(deep=True)\n",
    "df5 = df_temp[df_temp['log4'].notnull()].copy(deep=True)\n",
    "train1 = df4.drop(['log4', 'log1', 'log2'], axis=1)\n",
    "train2 = df5.drop(['log3', 'log1', 'log2'], axis=1)\n",
    "train1.rename(columns = {'log3':'log'}, inplace = True)\n",
    "train2.rename(columns = {'log4':'log'}, inplace = True)\n",
    "tmp_list = [train1,train2]\n",
    "train = pd.concat(tmp_list)\n",
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366ba3d3",
   "metadata": {},
   "source": [
    "# Trying to deal with the imbalance in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db532e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1\n",
    "# doing a 50 50 split\n",
    "\n",
    "train_new1 = train.sample(frac=1)\n",
    "\n",
    "fraud_df = train_new1.loc[train_new1['status'] == \"abnormal\"]\n",
    "non_fraud_df = train_new1.loc[train_new1['status'] == \"normal\"][:69692]\n",
    "\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "balanced_train1 = normal_distributed_df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2\n",
    "# Over sampling- making copies of the minority class\n",
    "\n",
    "X = df.drop(‘diagnosis’,axis=1)\n",
    "y = df[‘diagnosis’]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "#split data into test and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
    "#combine them back for resampling\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "# separate minority and majority classes\n",
    "negative = train_data[train_data.diagnosis==0]\n",
    "positive = train_data[train_data.diagnosis==1]\n",
    "# upsample minority\n",
    "pos_upsampled = resample(positive,\n",
    " replace=True, # sample with replacement\n",
    " n_samples=len(negative), # match number in majority class\n",
    " random_state=27) # reproducible results\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([negative, pos_upsampled])\n",
    "# check new class counts\n",
    "upsampled.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 3\n",
    "# downsample majority\n",
    "\n",
    "neg_downsampled = resample(negative,\n",
    " replace=True, # sample with replacement\n",
    " n_samples=len(positive), # match number in minority class\n",
    " random_state=27) # reproducible results\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([positive, neg_downsampled])\n",
    "# check new class counts\n",
    "downsampled.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 4\n",
    "# over sampling using smote \n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Separate input features and target\n",
    "X = df.drop(‘diagnosis’,axis=1)\n",
    "y = df[‘diagnosis’]\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "sm = SMOTE(random_state=27, ratio=1.0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "X_train.shape, y_train.shape\n",
    "((314, 5), (314,)) #We now have 314 data items in our training set\n",
    "y_train = pd.DataFrame(y_train, columns = ['diagnosis'])\n",
    "y_train.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f23263",
   "metadata": {},
   "source": [
    "# Tokenizer \n",
    "### Tokenizer is used to split sentences to words or chracters etc\n",
    "###### (Specific libraries do their own shit tho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer 1\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import re\n",
    "\n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(new_df['log3'].values)\n",
    "X = tokenizer.texts_to_sequences(new_df['log3'].values)\n",
    "X = pad_sequences(X)\n",
    "\n",
    "Y = pd.get_dummies(new_df['status']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer 2\n",
    "# reference -> https://www.kaggle.com/code/ashokkumarpalivela/sentiment-analysis-with-machine-learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense , LSTM , Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "# transform\n",
    "tfidf_X_train = tfidf_vectorizer.transform(X_train)\n",
    "tfidf_X_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c730b564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed109ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee7841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f169d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5ee0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08179fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f0d5a2c",
   "metadata": {},
   "source": [
    "# Vectorizer\n",
    "### Vectorizer converts words to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4c63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29119a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b75a473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a566ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9abeb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bc7747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2ba8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59921aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33d5a8b4",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1 used with tokenizer 1\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "model.fit(X_train, Y_train, epochs = 2, batch_size=batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5165928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference for the above shjit -> https://www.kaggle.com/code/sanjay11100/lstm-sentiment-analysis-data-imbalance-keras/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "853660ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186019cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52370977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e1d610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce41950",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb41407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization done using tokenizer 1 \n",
    "train_model3 = model3.fit(X_train, Y_train)\n",
    "pred3 = train_model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82994369",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e3e39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30cf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8a9f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f6c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d58d082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31f4170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3509a75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a57e964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2638b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16945b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3854f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083bd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dec18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1cf73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

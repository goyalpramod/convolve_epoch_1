{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2033bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajag\\Desktop\\convolve\\convolve_epoch_1\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e813d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajag\\Desktop\\convolve\\convolve_epoch_1\\data\n"
     ]
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88f4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6528093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom settings \n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be30d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data \n",
    "with open('train.json', 'r') as f:\n",
    "    dict_train = json.load(f)\n",
    "\n",
    "df = pd.DataFrame.from_dict(dict_train, orient='index')\n",
    "df.reset_index(level=0, inplace=True)\n",
    "df.rename(columns = {'index':'log',0:'status'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "296315da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "df_parsed = df.copy(deep=True)\n",
    "df_parsed[\"log\"]= df_parsed[\"log\"].str.split(\":\", n = 3, expand = False)\n",
    "df_temp = df_parsed.copy(deep=True)\n",
    "df_temp = pd.DataFrame(df_parsed['log'].to_list(), columns=['log1','log2','log3','log4'])\n",
    "df_temp['status'] = df_parsed['status']\n",
    "df4 = df_temp[df_temp['log4'].isnull()].copy(deep=True)\n",
    "df5 = df_temp[df_temp['log4'].notnull()].copy(deep=True)\n",
    "train1 = df4.drop(['log4', 'log1', 'log2'], axis=1)\n",
    "train2 = df5.drop(['log3', 'log1', 'log2'], axis=1)\n",
    "train1.rename(columns = {'log3':'log'}, inplace = True)\n",
    "train2.rename(columns = {'log4':'log'}, inplace = True)\n",
    "tmp_list = [train1,train2]\n",
    "train = pd.concat(tmp_list)\n",
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fdfd68",
   "metadata": {},
   "source": [
    "# Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa66439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2022/02/sentiment-analysis-using-transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a653587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "466d2fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1[\"status\"] = train1[\"status\"].map({\"abnormal\": 0, \"normal\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0fd7dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 5, custom sampler\n",
    "total_normal = train1[train1[\"status\"] == 1]\n",
    "total_abnormal = train1[train1[\"status\"] == 0]\n",
    "\n",
    "sampled_total_normal = total_normal.sample(n=69692)\n",
    "\n",
    "normal_distributed_df = pd.concat([total_abnormal, sampled_total_normal])\n",
    "\n",
    "balanced_train2 = normal_distributed_df.sample(frac=1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e25918b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2606855</th>\n",
       "      <td>J14-U01 RAS KERNEL INFO generating core.16136\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445412</th>\n",
       "      <td>J12-U11 RAS KERNEL INFO 1005 floating point alignment exceptions\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150103</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087324</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4140189</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        log  \\\n",
       "2606855                     J14-U01 RAS KERNEL INFO generating core.16136\\n   \n",
       "2445412  J12-U11 RAS KERNEL INFO 1005 floating point alignment exceptions\\n   \n",
       "4150103                   J16-U01 RAS KERNEL FATAL data TLB error interrupt   \n",
       "4087324                   J16-U01 RAS KERNEL FATAL data TLB error interrupt   \n",
       "4140189                   J16-U01 RAS KERNEL FATAL data TLB error interrupt   \n",
       "\n",
       "         status  \n",
       "2606855       1  \n",
       "2445412       1  \n",
       "4150103       0  \n",
       "4087324       0  \n",
       "4140189       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2340d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccd200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "758dd1c8",
   "metadata": {},
   "source": [
    "# Method 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022fe145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/maroberti/fastai-with-transformers-bert-roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d10ba6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2606855</th>\n",
       "      <td>J14-U01 RAS KERNEL INFO generating core.16136\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445412</th>\n",
       "      <td>J12-U11 RAS KERNEL INFO 1005 floating point alignment exceptions\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150103</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087324</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4140189</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        log  \\\n",
       "2606855                     J14-U01 RAS KERNEL INFO generating core.16136\\n   \n",
       "2445412  J12-U11 RAS KERNEL INFO 1005 floating point alignment exceptions\\n   \n",
       "4150103                   J16-U01 RAS KERNEL FATAL data TLB error interrupt   \n",
       "4087324                   J16-U01 RAS KERNEL FATAL data TLB error interrupt   \n",
       "4140189                   J16-U01 RAS KERNEL FATAL data TLB error interrupt   \n",
       "\n",
       "         status  \n",
       "2606855       1  \n",
       "2445412       1  \n",
       "4150103       0  \n",
       "4087324       0  \n",
       "4140189       0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70056914",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q transformers\n",
    "pip install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe002fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastai==1.0.58 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers==2.5.1 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1181a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random \n",
    "\n",
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callback import *\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55ae57d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version : 1.0.58\n",
      "transformers version : 2.5.1\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "print('fastai version :', fastai.__version__)\n",
    "print('transformers version :', transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb41cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bae96901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = 42\n",
    "use_fp16 = False\n",
    "bs = 16\n",
    "\n",
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-base'\n",
    "\n",
    "# model_type = 'bert'\n",
    "# pretrained_model_name='bert-base-uncased'\n",
    "\n",
    "# model_type = 'distilbert'\n",
    "# pretrained_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "#model_type = 'xlm'\n",
    "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
    "\n",
    "# model_type = 'xlnet'\n",
    "# pretrained_model_name = 'xlnet-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7daded82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d222c858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.pretrained_model_archive_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c39677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to set the seed for generating random numbers.\n",
    "\n",
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb09baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdb32c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer():\n",
    "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.max_len\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str):\n",
    "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "            tokens = [CLS] + tokens + [SEP]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "            if self.model_type in ['xlnet']:\n",
    "                tokens = tokens + [SEP] +  [CLS]\n",
    "            else:\n",
    "                tokens = [CLS] + tokens + [SEP]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61289d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f40cd241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
    "\n",
    "    def __setstate__(self, state:dict):\n",
    "        self.itos = state['itos']\n",
    "        self.tokenizer = state['tokenizer']\n",
    "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d51cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d844dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da5c4c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sal', 'ut', 'Ġc', 'Ġest', 'Ġmo', 'i', ',', 'ĠHello', 'Ġit', 'Ġs', 'Ġme']\n",
      "[18111, 1182, 740, 3304, 7458, 118, 6, 20920, 24, 579, 162]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sal', 'ut', 'Ġc', 'Ġest', 'Ġmo', 'i', ',', 'ĠHello', 'Ġit', 'Ġs', 'Ġme']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a check i believe\n",
    "tokens = transformer_tokenizer.tokenize('Salut c est moi, Hello it s me')\n",
    "print(tokens)\n",
    "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "transformer_tokenizer.convert_ids_to_tokens(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9036a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15d7a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed = test.copy(deep=True)\n",
    "df_parsed[\" Log\"]= df_parsed[\" Log\"].str.split(\":\", n = 3, expand = False)\n",
    "df_temp = df_parsed.copy(deep=True)\n",
    "df_temp = pd.DataFrame(df_parsed[' Log'].to_list(), columns=['log1','log2','log3','log4'])\n",
    "# df_temp['status'] = df_parsed['status']\n",
    "df4 = df_temp[df_temp['log4'].isnull()].copy(deep=True)\n",
    "df5 = df_temp[df_temp['log4'].notnull()].copy(deep=True)\n",
    "train1 = df4.drop(['log4', 'log1', 'log2'], axis=1)\n",
    "train2 = df5.drop(['log3', 'log1', 'log2'], axis=1)\n",
    "train1.rename(columns = {'log3':'log'}, inplace = True)\n",
    "train2.rename(columns = {'log4':'log'}, inplace = True)\n",
    "tmp_list = [train1,train2]\n",
    "train = pd.concat(tmp_list)\n",
    "test = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8fa99f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J03-U11 RAS KERNEL INFO generating core.6463\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>J08-U01 RAS KERNEL INFO CE sym 35, at 0x06a7bd60, mask 0x40\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             log\n",
       "1            J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n\n",
       "2            J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n\n",
       "3                 J03-U11 RAS KERNEL INFO generating core.6463\\n\n",
       "4            J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n\n",
       "5  J08-U01 RAS KERNEL INFO CE sym 35, at 0x06a7bd60, mask 0x40\\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56279c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/13 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-4951be2da775>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m databunch = (TextList.from_df(balanced_train2, cols='log', processor=transformer_processor)\n\u001b[0m\u001b[0;32m      2\u001b[0m              \u001b[1;33m.\u001b[0m\u001b[0msplit_by_rand_pct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m              \u001b[1;33m.\u001b[0m\u001b[0mlabel_from_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'status'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#              .add_test(test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m              .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\fastai\\data_block.py\u001b[0m in \u001b[0;36m_inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_item_lists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelLists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_inner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\fastai\\data_block.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;34m\"Process the inner datasets.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0mxp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_processors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m         \u001b[1;31m#progress_bar clear the outputs so in some case warnings issued during processing disappear.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\fastai\\data_block.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, xp, yp, name, max_warn_items)\u001b[0m\n\u001b[0;32m    712\u001b[0m                     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mfilt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mfilt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\fastai\\data_block.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, processor)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlistify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\fastai\\text\\data.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, ds)\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mtokens\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m         \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\fastai\\text\\transform.py\u001b[0m in \u001b[0;36mprocess_all\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_cpus\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_all_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_cpus\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_all_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartition_by_cores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_cpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mVocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[0mcareful\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0mto\u001b[0m \u001b[0myielded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \"\"\"\n\u001b[1;32m--> 484\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m         \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    609\u001b[0m                     \u001b[1;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "databunch = (TextList.from_df(balanced_train2, cols='log', processor=transformer_processor)\n",
    "             .split_by_rand_pct(0.1,seed=seed)\n",
    "             .label_from_df(cols= 'status')\n",
    "             .add_test(test)\n",
    "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "databunch.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f912f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
    "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
    "print('[PAD] id :', pad_idx)\n",
    "test_one_batch = databunch.one_batch()[0]\n",
    "print('Batch shape : ',test_one_batch.shape)\n",
    "print(test_one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ca5c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more to do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51788ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae9b3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce9616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84f6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6fcd0bf",
   "metadata": {},
   "source": [
    "# Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/approaches-to-sentimental-analysis-on-a-small-imbalanced-dataset-without-deep-learning-a314817e687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6c136f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b947285a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 595300 entries, 0 to 595299\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   ID      595300 non-null  int64 \n",
      " 1    Log    595300 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8ae59ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1124336301 2005.08.17 R13-M1-N8-C:J12-U01 2005-08-17-20.38.21.466368 R13-M1-N8-C:J12-U01 RAS KERNEL FATAL rts: kernel terminated for reason 1001\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1118553175 2005.06.11 R30-M0-N9-C:J16-U01 2005-06-11-22.12.55.707149 R30-M0-N9-C:J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1118536033 2005.06.11 R30-M0-N9-C:J16-U01 2005-06-11-17.27.13.042387 R30-M0-N9-C:J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1117992566 2005.06.05 R30-M1-N6-C:J03-U11 2005-06-05-10.29.26.943462 R30-M1-N6-C:J03-U11 RAS KERNEL INFO generating core.6463\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1118538965 2005.06.11 R30-M0-N9-C:J16-U01 2005-06-11-18.16.05.049256 R30-M0-N9-C:J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1118074540 2005.06.06 R15-M0-N0-C:J08-U01 2005-06-06-09.15.40.112852 R15-M0-N0-C:J08-U01 RAS KERNEL INFO CE sym 35, at 0x06a7bd60, mask 0x40\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1118541623 2005.06.11 R30-M0-N9-C:J16-U01 2005-06-11-19.00.23.903646 R30-M0-N9-C:J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1118149822 2005.06.07 R21-M0-N4-C:J17-U11 2005-06-07-06.10.22.237271 R21-M0-N4-C:J17-U11 RAS KERNEL INFO generating core.2364\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1118553027 2005.06.11 R30-M0-N9-C:J16-U01 2005-06-11-22.10.27.830555 R30-M0-N9-C:J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1118171330 2005.06.07 R23-M0-N0-I:J18-U01 2005-06-07-12.08.50.515997 R23-M0-N0-I:J18-U01 RAS KERNEL INFO ciod: Message code 0 is not 51 or 4294967295\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "5   5   \n",
       "6   6   \n",
       "7   7   \n",
       "8   8   \n",
       "9   9   \n",
       "\n",
       "                                                                                                                                                        Log  \n",
       "0        1124336301 2005.08.17 R13-M1-N8-C:J12-U01 2005-08-17-20.38.21.466368 R13-M1-N8-C:J12-U01 RAS KERNEL FATAL rts: kernel terminated for reason 1001\\n  \n",
       "1                      1118553175 2005.06.11 R30-M0-N9-C:J16-U01 2005-06-11-22.12.55.707149 R30-M0-N9-C:J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n  \n",
       "2                      1118536033 2005.06.11 R30-M0-N9-C:J16-U01 2005-06-11-17.27.13.042387 R30-M0-N9-C:J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n  \n",
       "3                           1117992566 2005.06.05 R30-M1-N6-C:J03-U11 2005-06-05-10.29.26.943462 R30-M1-N6-C:J03-U11 RAS KERNEL INFO generating core.6463\\n  \n",
       "4                      1118538965 2005.06.11 R30-M0-N9-C:J16-U01 2005-06-11-18.16.05.049256 R30-M0-N9-C:J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n  \n",
       "5            1118074540 2005.06.06 R15-M0-N0-C:J08-U01 2005-06-06-09.15.40.112852 R15-M0-N0-C:J08-U01 RAS KERNEL INFO CE sym 35, at 0x06a7bd60, mask 0x40\\n  \n",
       "6                      1118541623 2005.06.11 R30-M0-N9-C:J16-U01 2005-06-11-19.00.23.903646 R30-M0-N9-C:J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n  \n",
       "7                           1118149822 2005.06.07 R21-M0-N4-C:J17-U11 2005-06-07-06.10.22.237271 R21-M0-N4-C:J17-U11 RAS KERNEL INFO generating core.2364\\n  \n",
       "8                      1118553027 2005.06.11 R30-M0-N9-C:J16-U01 2005-06-11-22.10.27.830555 R30-M0-N9-C:J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n  \n",
       "9   1118171330 2005.06.07 R23-M0-N0-I:J18-U01 2005-06-07-12.08.50.515997 R23-M0-N0-I:J18-U01 RAS KERNEL INFO ciod: Message code 0 is not 51 or 4294967295\\n  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "983d2a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parsed = test.copy(deep=True)\n",
    "df_parsed[\" Log\"]= df_parsed[\" Log\"].str.split(\":\", n = 3, expand = False)\n",
    "df_temp = df_parsed.copy(deep=True)\n",
    "df_temp = pd.DataFrame(df_parsed[' Log'].to_list(), columns=['log1','log2','log3','log4'])\n",
    "df_temp['ID'] = df_parsed['ID']\n",
    "df4 = df_temp[df_temp['log4'].isnull()].copy(deep=True)\n",
    "df5 = df_temp[df_temp['log4'].notnull()].copy(deep=True)\n",
    "train1 = df4.drop(['log4', 'log1', 'log2'], axis=1)\n",
    "train2 = df5.drop(['log3', 'log1', 'log2'], axis=1)\n",
    "train1.rename(columns = {'log3':'log'}, inplace = True)\n",
    "train2.rename(columns = {'log4':'log'}, inplace = True)\n",
    "tmp_list = [train1,train2]\n",
    "train = pd.concat(tmp_list)\n",
    "test = train\n",
    "# test = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6e17132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.fillna(test.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2fa77bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 595300 entries, 1 to 595295\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   log     595300 non-null  object\n",
      " 1   ID      595300 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 13.6+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "07fbc266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J03-U11 RAS KERNEL INFO generating core.6463\\n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>J08-U01 RAS KERNEL INFO CE sym 35, at 0x06a7bd60, mask 0x40\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>J17-U11 RAS KERNEL INFO generating core.2364\\n</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>J14-U01 RAS KERNEL INFO generating core.228\\n</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>J12-U11 RAS KERNEL INFO instruction cache parity error corrected\\n</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   log  ID\n",
       "1                  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   1\n",
       "2                  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   2\n",
       "3                       J03-U11 RAS KERNEL INFO generating core.6463\\n   3\n",
       "4                  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   4\n",
       "5        J08-U01 RAS KERNEL INFO CE sym 35, at 0x06a7bd60, mask 0x40\\n   5\n",
       "6                  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   6\n",
       "7                       J17-U11 RAS KERNEL INFO generating core.2364\\n   7\n",
       "8                  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   8\n",
       "10                       J14-U01 RAS KERNEL INFO generating core.228\\n  10\n",
       "11  J12-U11 RAS KERNEL INFO instruction cache parity error corrected\\n  11"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c5d2fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.sort_values(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e9d77cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kernel terminated for reason 1001\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J03-U11 RAS KERNEL INFO generating core.6463\\n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>J08-U01 RAS KERNEL INFO CE sym 35, at 0x06a7bd60, mask 0x40\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>J17-U11 RAS KERNEL INFO generating core.2364\\n</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Message code 0 is not 51 or 4294967295\\n</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             log  ID\n",
       "0                            kernel terminated for reason 1001\\n   0\n",
       "1            J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   1\n",
       "2            J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   2\n",
       "3                 J03-U11 RAS KERNEL INFO generating core.6463\\n   3\n",
       "4            J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   4\n",
       "5  J08-U01 RAS KERNEL INFO CE sym 35, at 0x06a7bd60, mask 0x40\\n   5\n",
       "6            J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   6\n",
       "7                 J17-U11 RAS KERNEL INFO generating core.2364\\n   7\n",
       "8            J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   8\n",
       "9                       Message code 0 is not 51 or 4294967295\\n   9"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3c954cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = balanced_train2.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ecc9c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc5b9573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajag\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), tokenizer=tokenizer.tokenize)\n",
    "full_text = list(train['log'].values) + list(test['log'].values)\n",
    "vectorizer.fit(full_text)\n",
    "train_vectorized = vectorizer.transform(train['log'])\n",
    "test_vectorized = vectorizer.transform(test['log'])\n",
    "y = train['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f648c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "logreg = LogisticRegression(class_weight='balanced')\n",
    "ovr = OneVsRestClassifier(logreg).fit(train_vectorized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3614f370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139384"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "96b39b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation mean f1_score 1.00%, std 0.00.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(ovr, train_vectorized, y, scoring='f1_macro', n_jobs=-1, cv=3)\n",
    "print('Cross-validation mean f1_score {0:.2f}%, std {1:.2f}.'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8783381d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<595300x198716 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14625118 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5dedaffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ovr.predict_proba(test_vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b3317cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more shit in the article to make it better, but first..... check this on the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e8f988b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595300"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "82c39bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595300"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5d383390",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in pred.argmax(1):\n",
    "    if i == 0:\n",
    "        count += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7fad94ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27696287586091045"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "164876/595300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9b9c6838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164876\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fae11933",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "70a81146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kernel terminated for reason 1001\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J03-U11 RAS KERNEL INFO generating core.6463\\n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   log  ID\n",
       "0                  kernel terminated for reason 1001\\n   0\n",
       "1  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   1\n",
       "2  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   2\n",
       "3       J03-U11 RAS KERNEL INFO generating core.6463\\n   3\n",
       "4  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   4"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a3906d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kernel terminated for reason 1001\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J03-U11 RAS KERNEL INFO generating core.6463\\n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   log  ID\n",
       "0                  kernel terminated for reason 1001\\n   0\n",
       "1  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   1\n",
       "2  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   2\n",
       "3       J03-U11 RAS KERNEL INFO generating core.6463\\n   3\n",
       "4  J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   4"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6a823fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595300"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2ba0d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['status'] = pred.argmax(1)\n",
    "# sub.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "826bc3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>ID</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kernel terminated for reason 1001\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>J03-U11 RAS KERNEL INFO generating core.6463\\n</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>J08-U01 RAS KERNEL INFO CE sym 35, at 0x06a7bd60, mask 0x40\\n</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>J17-U11 RAS KERNEL INFO generating core.2364\\n</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Message code 0 is not 51 or 4294967295\\n</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>J14-U01 RAS KERNEL INFO generating core.228\\n</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>J12-U11 RAS KERNEL INFO instruction cache parity error corrected\\n</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>J05-U01 RAS KERNEL INFO generating core.4279\\n</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>J15-U01 RAS KERNEL INFO generating core.7572\\n</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33240\\n</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            log  \\\n",
       "0                                                           kernel terminated for reason 1001\\n   \n",
       "1                                           J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   \n",
       "2                                           J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   \n",
       "3                                                J03-U11 RAS KERNEL INFO generating core.6463\\n   \n",
       "4                                           J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   \n",
       "5                                 J08-U01 RAS KERNEL INFO CE sym 35, at 0x06a7bd60, mask 0x40\\n   \n",
       "6                                           J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   \n",
       "7                                                J17-U11 RAS KERNEL INFO generating core.2364\\n   \n",
       "8                                           J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   \n",
       "9                                                      Message code 0 is not 51 or 4294967295\\n   \n",
       "10                                                J14-U01 RAS KERNEL INFO generating core.228\\n   \n",
       "11                           J12-U11 RAS KERNEL INFO instruction cache parity error corrected\\n   \n",
       "12                                          J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   \n",
       "13                                               J05-U01 RAS KERNEL INFO generating core.4279\\n   \n",
       "14                                          J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   \n",
       "15                                               J15-U01 RAS KERNEL INFO generating core.7572\\n   \n",
       "16                                          J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   \n",
       "17                                          J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   \n",
       "18   failed to read message prefix on control stream (CioStream socket to 172.16.96.116:33240\\n   \n",
       "19                                          J16-U01 RAS KERNEL FATAL data TLB error interrupt\\n   \n",
       "\n",
       "    ID  status  \n",
       "0    0       1  \n",
       "1    1       0  \n",
       "2    2       0  \n",
       "3    3       1  \n",
       "4    4       0  \n",
       "5    5       1  \n",
       "6    6       0  \n",
       "7    7       1  \n",
       "8    8       0  \n",
       "9    9       1  \n",
       "10  10       1  \n",
       "11  11       1  \n",
       "12  12       0  \n",
       "13  13       1  \n",
       "14  14       0  \n",
       "15  15       1  \n",
       "16  16       0  \n",
       "17  17       0  \n",
       "18  18       0  \n",
       "19  19       0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a61b61e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = sub.drop(['log'], axis=1)\n",
    "sub.rename(columns = {'status':'Label',}, inplace = True)\n",
    "sub[\"Label\"] = sub[\"Label\"].map({0:\"abnormal\",1:\"normal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4a921737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID     Label\n",
       "0    0    normal\n",
       "1    1  abnormal\n",
       "2    2  abnormal\n",
       "3    3    normal\n",
       "4    4  abnormal\n",
       "5    5    normal\n",
       "6    6  abnormal\n",
       "7    7    normal\n",
       "8    8  abnormal\n",
       "9    9    normal\n",
       "10  10    normal\n",
       "11  11    normal\n",
       "12  12  abnormal\n",
       "13  13    normal\n",
       "14  14  abnormal\n",
       "15  15    normal\n",
       "16  16  abnormal\n",
       "17  17  abnormal\n",
       "18  18  abnormal\n",
       "19  19  abnormal"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e55d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so my drop na is droping about 1000 rows, so un sabka i can set 1 by default. Rest ka i have to map  the id and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "83e858b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595300"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "15578410",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(r'C:\\Users\\rajag\\Desktop\\convolve\\convolve_epoch_1\\submission\\submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac7d0537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajag\\Desktop\\convolve\\convolve_epoch_1\\submission\n"
     ]
    }
   ],
   "source": [
    "cd submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d210145",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a80ceea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     Label\n",
       "0   0    normal\n",
       "1   1  abnormal\n",
       "2   2  abnormal\n",
       "3   3    normal\n",
       "4   4  abnormal"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16239f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.rename(columns = {'Label':' Label'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d73a6160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 595300 entries, 0 to 595299\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   ID      595300 non-null  int64 \n",
      " 1    Label  595300 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98c116af",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r'C:\\Users\\rajag\\Desktop\\convolve\\convolve_epoch_1\\submission\\submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6262f09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595300"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a4c7a1",
   "metadata": {},
   "source": [
    "# method 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/timurrashitov/bert-transfer-learning-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1050c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet wandb\n",
    "!pip install --quiet transformers\n",
    "!pip install --quiet datasets\n",
    "!pip install --quiet emoji\n",
    "!pip install --quiet kaggle\n",
    "!pip install --quiet torchinfo\n",
    "!pip install --quiet imbalanced-learn\n",
    "!pip install --quiet gdown\n",
    "\n",
    "# my login - timakaznet, hust regirster wanbd account and u'll take trial period which is enough\n",
    "! wandb login fa19cfab8c0967bc35372f9f40932d67154809a9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a236545",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet clean-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2792b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from torch.utils import data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# data processing\n",
    "import re, string\n",
    "import emoji\n",
    "import nltk\n",
    "\n",
    "# dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "from datasets import Dataset , Sequence , Value , Features , ClassLabel , DatasetDict\n",
    "\n",
    "# preprocessing\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import re, string\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of pretrained models: https://huggingface.co/transformers/v3.3.1/pretrained_models.html\n",
    "models = [\"distilbert-base-uncased\", \"bert-base-uncased\", \"bert-base-cased\"]\n",
    "modelName = models[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use raw df, should have only teo columns, log and status\n",
    "# Make the status 1 and 0\n",
    "df_train = df.copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8641d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973aae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word tokenizer\n",
    "df_train['Reviews_len_by_words'] = df_train['Reviews'].apply(lambda t: len(t.split()))\n",
    "min_len_word, max_len_word = df_train['Reviews_len_by_words'].min(), df_train['Reviews_len_by_words'].max()\n",
    "print(min_len_word, max_len_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24585a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the status 1 and 0\n",
    "df_test = test.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c882579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffle series\n",
    "# df_train = df_train.sample(frac=1, random_state=RANDOM_SEED)\n",
    "\n",
    "print(df_train.shape , df_test.shape)\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.09, random_state=RANDOM_SEED, stratify=df_train['Sentiment'])\n",
    "print(df_train.shape , df_val.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset(df, textCol, labelCol):\n",
    "  dataset_dict = {\n",
    "    'text' : df[textCol],\n",
    "    'labels' : df[labelCol],\n",
    "  }\n",
    "  sent_tags = ClassLabel(num_classes=5 , names=['Extremely Negative', 'Negative','Neutral','Positive', 'Extremely Positive'])\n",
    "\n",
    "  return Dataset.from_dict(\n",
    "    mapping = dataset_dict,\n",
    "    features = Features({'text' : Value(dtype='string') , 'labels' :sent_tags})\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b6445",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = createDataset(df_train,\"Reviews\",\"Sentiment\")\n",
    "dataset_val = createDataset(df_val,\"Reviews\",\"Sentiment\")\n",
    "dataset_test = createDataset(df_test,\"Reviews\",\"Sentiment\")\n",
    "\n",
    "dataset_sentAnalysis = DatasetDict()\n",
    "dataset_sentAnalysis[\"train\"] = dataset_train\n",
    "dataset_sentAnalysis[\"val\"] = dataset_val\n",
    "dataset_sentAnalysis[\"test\"] = dataset_test\n",
    "\n",
    "dataset_sentAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72792d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_emojis(text):\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text) #remove links and mentions\n",
    "    text = re.sub(r\"<.*?>\",\"\",text)\n",
    "\n",
    "    wierd_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u'\\U00010000-\\U0010ffff'\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\u3030\"\n",
    "        u\"\\ufe0f\"\n",
    "        u\"\\u2069\"\n",
    "        u\"\\u2066\"\n",
    "        # u\"\\u200c\"\n",
    "        u\"\\u2068\"\n",
    "        u\"\\u2067\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    return wierd_pattern.sub(r'', text)\n",
    "\n",
    "def remove_numbers(text):\n",
    "    number_pattern = r'\\d+'\n",
    "    without_number = re.sub(pattern=number_pattern, repl=\" \", string=text)\n",
    "    return without_number\n",
    "\n",
    "def lemmatizing(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text)\n",
    "    for i in range(len(tokens)):\n",
    "        lemma_word = lemmatizer.lemmatize(tokens[i])\n",
    "        tokens[i] = lemma_word\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    removed = []\n",
    "    stop_words = list(stopwords.words(\"english\"))\n",
    "    tokens = word_tokenize(text)\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] not in stop_words:\n",
    "            removed.append(tokens[i])\n",
    "    return \" \".join(removed)\n",
    "\n",
    "def remove_extra_white_spaces(text):\n",
    "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
    "    without_sc = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
    "    return without_sc\n",
    "\n",
    "def preprocessText(text):\n",
    "  return remove_extra_white_spaces(remove_stopwords(remove_punctuation(remove_numbers(remove_emojis(convert_to_lower(text))))))\n",
    "\n",
    "def preprocessBatch(batch):\n",
    "  new_list = []\n",
    "  for i in batch[\"text\"]:\n",
    "    new_list.append(remove_extra_white_spaces(remove_stopwords(remove_punctuation(remove_numbers(remove_emojis(convert_to_lower(i)))))))\n",
    "  batch[\"text\"] = new_list\n",
    "  return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sentAnalysis_preprocessed = dataset_sentAnalysis.map(preprocessBatch, batched=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sentAnalysis[\"train\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7891c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sentAnalysis_preprocessed[\"train\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b0d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea02f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 128\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ae6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sentAnalysis_encoded = dataset_sentAnalysis_preprocessed.map(tokenize, batched=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113ecba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sentAnalysis_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "from transformers.models.bert.modeling_bert import BertModel, BertPreTrainedModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import torch.nn as nn\n",
    "\n",
    "class BertForClassification(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        # Load model body > return all og the HS\n",
    "        self.bert = BertModel(config)\n",
    "        # Set up token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, \n",
    "                labels=None, **kwargs):\n",
    "        # Use model body to get encoder representations\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids, **kwargs)\n",
    "\n",
    "        # Apply classifier to encoder representation > [cls]\n",
    "        sequence_output = self.dropout(outputs[1])\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        # Calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        # Return model output object\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3eca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "id2label = {\n",
    "    0: 'Extremely Negative',\n",
    "    1: 'Negative',\n",
    "    2: 'Neutral',\n",
    "    3: 'Positive',\n",
    "    4: 'Extremely Positive'\n",
    "}\n",
    "\n",
    "label2id = { v:k for (k,v) in id2label.items()}\n",
    "\n",
    "bert_config = AutoConfig.from_pretrained(modelName, \n",
    "                                         num_labels=5,\n",
    "                                         id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042acf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = (BertForClassification\n",
    "              .from_pretrained(modelName, config=bert_config)\n",
    "              .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "wandb.init(project=\"bert-for-english-classification\")\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "logging_steps = len(dataset_sentAnalysis_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{modelName}-finetuned-sentimentAnalysis-bert\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\", \n",
    "                                  save_steps=1e6,\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=False, \n",
    "                                  log_level=\"error\",\n",
    "                                  report_to=\"wandb\",\n",
    "                                  run_name=\"bert-sent-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f10cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "optimizer = AdamW(bert_model.parameters(), lr=2e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "num_training_steps = num_epochs * logging_steps\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "trainer_preprocessed_lr = Trainer(model=bert_model, args=training_args,\n",
    "                                  compute_metrics=compute_metrics,\n",
    "                                  train_dataset=dataset_sentAnalysis_encoded[\"train\"],\n",
    "                                  eval_dataset=dataset_sentAnalysis_encoded[\"val\"],\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  optimizers=(optimizer,lr_scheduler))\n",
    "\n",
    "trainer_preprocessed_lr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bert_model\n",
    "model.eval()\n",
    "preds_output = trainer_preprocessed_lr.predict(dataset_sentAnalysis_encoded[\"test\"])\n",
    "pd.DataFrame(list(preds_output.metrics.items())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749de163",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./bert-classification-classification-head\"\n",
    "torch.save(bert_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f6bc0f",
   "metadata": {},
   "source": [
    "# Method 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/mnavaidd/xlnet-multi-class-text-classification-xlnet/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da5af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "#---------------------------------------Text Processing------------------------------------------------------------#\n",
    "import regex\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have the dataset ready here, log and status, both as string~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "for punct in punctuation:\n",
    "    stop.append(punct)\n",
    "\n",
    "def filter_text(text, stop_words):\n",
    "    word_tokens = WordPunctTokenizer().tokenize(text.lower())\n",
    "    filtered_text = [regex.sub(u'\\p{^Latin}', u'', w) for w in word_tokens if w.isalpha() and len(w) > 3]\n",
    "    filtered_text = [wordnet_lemmatizer.lemmatize(w, pos=\"v\") for w in filtered_text if not w in stop_words] \n",
    "    return \" \".join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0764a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# 2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFXLNetModel, XLNetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f545f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_model = 'xlnet-large-cased'\n",
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained(xlnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2166fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 1 #len(names)\n",
    "number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd8478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xlnet(mname):\n",
    "    \"\"\" Creates the model. It is composed of the XLNet main block and then\n",
    "    a classification head its added\n",
    "    \"\"\"\n",
    "    # Define token ids as inputs\n",
    "    word_inputs = tf.keras.Input(shape=(120,), name='word_inputs', dtype='int32')\n",
    "\n",
    "    # Call XLNet model\n",
    "    xlnet = TFXLNetModel.from_pretrained(mname)\n",
    "    xlnet_encodings = xlnet(word_inputs)[0]\n",
    "\n",
    "    # CLASSIFICATION HEAD \n",
    "    # Collect last step from last hidden state (CLS)\n",
    "    doc_encoding = tf.squeeze(xlnet_encodings[:, -1:, :], axis=1)\n",
    "    # Apply dropout for regularization\n",
    "    doc_encoding = tf.keras.layers.Dropout(.1)(doc_encoding)\n",
    "    # Final output \n",
    "    outputs = tf.keras.layers.Dense(number_of_classes, activation='sigmoid', name='outputs')(doc_encoding)\n",
    "\n",
    "    # Compile model\n",
    "    model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet = create_xlnet(xlnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcf6456",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39f7760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(data['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data['filtered_text']\n",
    "labels = data['Class']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, y, test_size=0.15, random_state=196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(text, tokenizer, max_len=512):\n",
    "    \"\"\" Gets tensors from text using the tokenizer provided\"\"\"\n",
    "    inps = [tokenizer.encode_plus(t, max_length=max_len, pad_to_max_length=True, add_special_tokens=True) for t in text]\n",
    "    inp_tok = np.array([a['input_ids'] for a in inps])\n",
    "    ids = np.array([a['attention_mask'] for a in inps])\n",
    "    segments = np.array([a['token_type_ids'] for a in inps])\n",
    "    return inp_tok, ids, segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup(epoch, lr):\n",
    "    \"\"\"Used for increasing the learning rate slowly, this tends to achieve better convergence.\n",
    "    However, as we are finetuning for few epoch it's not crucial.\n",
    "    \"\"\"\n",
    "    return max(lr +1e-6, 2e-5)\n",
    "\n",
    "def plot_metrics(pred, true_labels):\n",
    "    \"\"\"Plots a ROC curve with the accuracy and the AUC\"\"\"\n",
    "    acc = accuracy_score(true_labels, np.array(pred.flatten() >= .5, dtype='int'))\n",
    "    fpr, tpr, thresholds = roc_curve(true_labels, pred)\n",
    "    auc = roc_auc_score(true_labels, pred)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(8,8))\n",
    "    ax.plot(fpr, tpr, color='red')\n",
    "    ax.plot([0,1], [0,1], color='black', linestyle='--')\n",
    "    ax.set_title(f\"AUC: {auc}\\nACC: {acc}\");\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d3f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_tok, ids, segments = get_inputs(X_train, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f62b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4, min_delta=0.02, restore_best_weights=True),\n",
    "    tf.keras.callbacks.LearningRateScheduler(warmup, verbose=0),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=1e-6, patience=2, verbose=0, mode='auto', min_delta=0.001, cooldown=0, min_lr=1e-6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bef70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = xlnet.fit(x=inp_tok, y=y_train, epochs=4, batch_size=2, validation_split=.15, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43660c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf65155",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_tok, ids, segments = get_inputs(X_test, xlnet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c70928",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xlnet.predict(inp_tok, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58363278",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_analysis_df = pd.DataFrame({'tweet':X_test.values, 'pred':preds.flatten(), 'real':y_test})\n",
    "pred_analysis_df['rounded'] = np.array(pred_analysis_df['pred'] > 0.5, dtype='int')\n",
    "diff = pred_analysis_df[pred_analysis_df['real'] != pred_analysis_df['rounded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 44\n",
    "\n",
    "tweet, real, pred = diff.iloc[idx, [0,2,3]]\n",
    "print(tweet)\n",
    "print(\"PRED: \" + str(pred))\n",
    "print(\"REAL: \" + str(real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xlnet.predict(inp_tok, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d2927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataf_test['target'] = preds\n",
    "# dataf_test['target'] = np.array(dataf_test['target'] >= 0.5, dtype='int')\n",
    "# dataf_test[['id', 'target']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7981654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e1f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b483980",
   "metadata": {},
   "source": [
    "# method 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb911c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/mesutbilgin/real-fake-job-posting-prediciton-bidirtnl-lstm#5--Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ff083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# Nlp library\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk as nlp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# sklearn Library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "#Tenserflow Library\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding,  Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b7712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have the data with you "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddac796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\" \", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66985299",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "\n",
    "for text in df_last.text:\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    text = [word for word in text if not word in set(stopwords.words(\"english\"))] # dropping stopwords\n",
    "    lemma = nlp.WordNetLemmatizer()\n",
    "    text = [lemma.lemmatize(word) for word in text]\n",
    "    text = \" \".join(text)\n",
    "    text = text.replace('  ',' ')\n",
    "    text_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0094505",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb32f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tokenizer\n",
    "t = Tokenizer(num_words = max_features)\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261ebd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs = t.texts_to_sequences(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30ba9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_docs=pad_sequences(encoded_docs,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)# all reviews must be same lenght. we equals all reviews lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be23812",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.1, random_state= 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ab14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, prediction):\n",
    "    print(\"Accuracy Score: {}\".format(accuracy_score(actual, prediction)))\n",
    "    print(\"Recall Score: {}\".format(recall_score(actual, prediction)))\n",
    "    print(\"f1 Score: {}\".format(f1_score(actual, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ecb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_features=40\n",
    "model1=Sequential()\n",
    "model1.add(Embedding(max_features,embedding_vector_features,input_length=sent_length))\n",
    "model1.add(Bidirectional(LSTM(20 )))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy']) # make this f1 score\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde66655",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e3dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "cp = ModelCheckpoint(\"./bidirectional_model/\" ,save_best_only = True)## creaitng model checkpoint\n",
    "hist = model1.fit(X_train, y_train, epochs = 5, batch_size = 64,  callbacks = cp, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d8fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['val_loss'], color='b', label=\"validation loss\")\n",
    "plt.plot(hist.history['loss'], color='red', label=\"loss\")\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2132b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['val_loss'], color='b', label=\"validation loss\")\n",
    "plt.plot(hist.history['loss'], color='red', label=\"loss\")\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd601a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = (y_train_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8f4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ace51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e431679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
